{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lv6DO-LM_aMn"
   },
   "source": [
    "# Práctica spark sql (Etapa 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ASxqaXhcRt7m"
   },
   "source": [
    "## Construcción del módulo toronto_bike\n",
    "\n",
    "En esta etapa y con lo experimentado en la etapa anterior, vamos a crear un paquete de python, que posteriormente instalaremos en un environment para realizar ciertas pruebas. \n",
    "\n",
    "Como hemos visto en el portal de datos abiertos de Toronto (https://open.toronto.ca/dataset/bike-share-toronto-ridership-data/), los ficheros de datos se encunetran en el repositorio CKAN.\n",
    "\n",
    "__Instrucciones para la creación del módulo `toronto_bike`__\n",
    "\n",
    "El módulo `toronto_bike` debe exportar las clases `UrlToronto` y `BikeToronto` descritas a continuación.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clase `UrlToronto`\n",
    "\n",
    "Vamos a crear una clase que permita recopilar todos los enlaces relacionados con el uso de bicicletas que hay en el portal de datos abiertos de Toronto (https://open.toronto.ca/dataset/bike-share-toronto-ridership-data/). Los enlaces que cumplen esta restricción son los que denominaremos a partir de ahora _enlaces válidos_. Estos enlaces contienen la cadena `bikeshare-ridership-YYYY.zip` donde `YYYY` representa el año.\n",
    "\n",
    "\n",
    "__Requisitos:__\n",
    "\n",
    "* Los datos se encuentran en CKAN, por lo que usaremos su API para la descarga. La clase ha de contener una constante de clase:\n",
    "```\n",
    "BASE_URL = \"https://ckan0.cf.opendata.inter.prod-toronto.ca\"\n",
    "```\n",
    "* Los objetos de la clase tienen __dos atributos__:\n",
    "    * _temporal_path_: ubicación temporal donde se descargarán los datos  de los ficheros csv que necesitemos para crear nuestros dataframes.\n",
    "    * _valid_urls_: lista de nombres de ficheros ZIP que se corresponden con la información de uso de bicicletas (uno por año).\n",
    "\n",
    "\n",
    "* Ha de contener al menos los siguientes métodos:\n",
    "\n",
    "    * `__init__`: método constructor con un argumento (ubicación temporal).\n",
    "    *  `select_valid_urls`: método estático que se encarga de actualizar el atributo  _valid_urls_ de los objetos de la clase. Devuelve un conjunto de enlaces válidos. Si la petición al servidor devuelve un código de retorno distinto de 200, la función lanza una excepción de tipo `ConnectionError`. A continuación se muestra un fragmento de código que permite extraer información de dichos enlaces(consultar apartado __FOR DEVELOPERS__ de la url https://open.toronto.ca/dataset/bike-share-toronto-ridership-data/), y que puede servir como base para desarrrollar el método  `select_valid_urls`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Toronto Open Data is stored in a CKAN instance. It's APIs are documented here:\n",
    "# https://docs.ckan.org/en/latest/api/\n",
    "\n",
    "# To hit our API, you'll be making requests to:\n",
    "base_url = \"https://ckan0.cf.opendata.inter.prod-toronto.ca\"\n",
    "\n",
    "# Datasets are called \"packages\". Each package can contain many \"resources\"\n",
    "# To retrieve the metadata for this package and its resources, use the package name in this page's URL:\n",
    "url = base_url + \"/api/3/action/package_show\"\n",
    "params = { \"id\": \"bike-share-toronto-ridership-data\"}\n",
    "package = requests.get(url, params = params).json()\n",
    "\n",
    "# To get resource data:\n",
    "for _, resource in enumerate(package[\"result\"][\"resources\"]):\n",
    "\n",
    "       # To get metadata for non datastore_active resources:\n",
    "       if not resource[\"datastore_active\"]:\n",
    "           url = base_url + \"/api/3/action/resource_show?id=\" + resource[\"id\"]\n",
    "           resource_metadata = requests.get(url).json()\n",
    "           print(resource_metadata)\n",
    "           # From here, you can use the \"url\" attribute to download this file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `download_csv`:  método de instancia que acepta los argumentos de tipo entero `month` y `year` y devuelve el string de la ruta del fichero  CSV correspondiente al mes `month` y año `year`. Este fichero se extrae del ZIP correspondiente que ha de estar en _valid_urls_. Se lanzará una excepción de tipo `ValueError` en caso de que no exista. Se deberá comprobar que el mes y año se corresponden con valores válidos (`month` entre 1 y 12, `year` entre 20 y 23). Si la petición al servidor devuelve un código de retorno distinto de 200, la función lanza una excepción de tipo `ConnectionError`. A continuación dejo un posible esqueleto (casi completo):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def download_csv(self, year:str, month:str)-> str:\n",
    "        \"\"\"\n",
    "        TODO completar el docstring. No olvidéis las excepciones\n",
    "        :param year:\n",
    "        :param month:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # temporal_path: ruta elegida donde se guardará el fichero CSV descomprimido\n",
    "        temporal_path =  ...    # ruta donde se guardará el fichero CSV descomprimido\n",
    "        # url: será la url donde se encuentran los datos (para year = 2023, esta url se corresponde con un ZIP con 12 ficheros, uno para cada mes )\n",
    "        url =   ...   \n",
    "        # name: nombre del fichero que nos intersa ( puede ser parte del nombre, algo de tipo '2023-05.csv')\n",
    "        name = ...    # nombre del fichero que nos intersa ( algo de tipo '2023-05.csv') \n",
    "        response = requests.get(url)     # petición\n",
    "        if response.status_code == 200:\n",
    "            content = io.BytesIO(response.content)     \n",
    "            zfile = zipfile.ZipFile(content, 'r')\n",
    "            files = [f for f in zfile.filelist if f.filename.find(name) > 0]      # devuelve una lista unitaria con el fichero que nos interesa\n",
    "            # nombre del fichero a extraer:\n",
    "            print(files)\n",
    "            \n",
    "            # Extraemos el contenido en una carpeta temporal\n",
    "            os.makedirs(temporal_path, exist_ok=True)                               # Creamos la carpeta temporal\n",
    "            zfile.extractall(temporal_path, members=files)                          # extraemos del ZIP solo el fichero que nos interesa\n",
    "\n",
    "            # nombre del fichero csv :\n",
    "            file_path = os.path.join(temporal_path, files[0].filename)              # me guardo la ruta a dicho fichero\n",
    "            return file_path\n",
    "        else:\n",
    "            raise ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Cuidado__: mirando el año 2022, nos encontramos con que no existe fichero ' ... 2022-11.csv'. Sin embargo, sí existe el fichero ' ... 2022-11.zip'. En estos caso, tendremos que extraer el csv que hay dentro, y por tanto modificar el código de forma apropiada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Clase `BikeToronto`\n",
    "\n",
    "Vamos a crear una clase que permita crear un dataframe de pySpark con los datos de uso de las bicicletas en un mes y año concreto. Además, esta clase proporcionará ciertas operaciones para realizar limpieza y cierto análisis básico de los datos.\n",
    "\n",
    "__Requisitos:__\n",
    "\n",
    "* Los objetos de la clase tienen dos atributos (spark, parametros) que representan:\n",
    "\n",
    "    * spark: la instancia de spark (recupera la SparkSession, si es que ya existe, o crea una nueva)\n",
    "    * parametros: diccionario creado a partir de los datos del fichero json que se proporciona (_parametros.json_)\n",
    "\n",
    "* Ha de contener al menos los siguientes métodos:\n",
    "\n",
    "    * `__init__`: método constructor. Acepta un argumento de tipo `str` que representa la ruta al fichero json que contiene los parámetros de la clase.\n",
    "    * `crear_df`: método de instancia que acepta los argumentos `month` y `year` (ambos de tipo `str`) y devuelve un objeto de tipo DataFrame de Spark con los datos de uso correspondientes al mes `month` y año  `year`. \n",
    "    * `procesar_df`_: método que acepta como argumento de entrada un dataframe de Spark y devuelve dos dataframes. Este método debe:        \n",
    "        \n",
    "        *  Eliminar filas duplicadas del dataframe de entrada\n",
    "        *  Los tipos de cada una de las columnas han de ser los siguientes:  Start Time y End Time: fecha, User Type, Start Station Name y End Station Name: string.  El resto son de tipo entero.\n",
    "        *  Las columnas que nos interesan son: Trip Duration, \tStart Station Id, \tStart Time, \tStart Station Name, \tEnd Station Id, \tEnd Time, \tEnd Station Name, y \tBike Id.\n",
    "        * Trip Duration viene expresado en segundos. Añadir una nueva columna con la duración en minutos.\n",
    "        *  Se devolverán dos dataframes, uno con los datos de los usuario de tipo Casual Member y otro con el resto de usuarios.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalamos el módulo  \n",
    "\n",
    "```\n",
    "pip install --force-reinstall  .\\dist\\toronto_bike-0.0.1-py3-none-any.whl\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probamos el módulo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing c:\\users\\mario\\downloads\\ej2\\dist\\toronto_bike-0.0.1-py3-none-any.whl\n",
      "Collecting requests (from toronto-bike==0.0.1)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting findspark (from toronto-bike==0.0.1)\n",
      "  Using cached findspark-2.0.1-py2.py3-none-any.whl.metadata (352 bytes)\n",
      "Collecting pyspark (from toronto-bike==0.0.1)\n",
      "  Using cached pyspark-3.5.4-py2.py3-none-any.whl\n",
      "Collecting py4j==0.10.9.7 (from pyspark->toronto-bike==0.0.1)\n",
      "  Using cached py4j-0.10.9.7-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->toronto-bike==0.0.1)\n",
      "  Using cached charset_normalizer-3.4.1-cp313-cp313-win_amd64.whl.metadata (36 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->toronto-bike==0.0.1)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->toronto-bike==0.0.1)\n",
      "  Using cached urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->toronto-bike==0.0.1)\n",
      "  Using cached certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
      "Using cached findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
      "Using cached py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Using cached charset_normalizer-3.4.1-cp313-cp313-win_amd64.whl (102 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Installing collected packages: py4j, findspark, urllib3, pyspark, idna, charset-normalizer, certifi, requests, toronto-bike\n",
      "  Attempting uninstall: py4j\n",
      "    Found existing installation: py4j 0.10.9.7\n",
      "    Uninstalling py4j-0.10.9.7:\n",
      "      Successfully uninstalled py4j-0.10.9.7\n",
      "  Attempting uninstall: findspark\n",
      "    Found existing installation: findspark 2.0.1\n",
      "    Uninstalling findspark-2.0.1:\n",
      "      Successfully uninstalled findspark-2.0.1\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.3.0\n",
      "    Uninstalling urllib3-2.3.0:\n",
      "      Successfully uninstalled urllib3-2.3.0\n",
      "  Attempting uninstall: pyspark\n",
      "    Found existing installation: pyspark 3.5.4\n",
      "    Uninstalling pyspark-3.5.4:\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 32] El proceso no tiene acceso al archivo porque está siendo utilizado por otro proceso: 'c:\\\\users\\\\mario\\\\appdata\\\\local\\\\programs\\\\python\\\\python313\\\\lib\\\\site-packages\\\\pyspark\\\\jars\\\\activation-1.1.1.jar'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%pip install --force-reinstall  .\\dist\\toronto_bike-0.0.1-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'toronto_bike.UrlToronto.UrlToronto'>\n"
     ]
    }
   ],
   "source": [
    "from  toronto_bike.UrlToronto import UrlToronto\n",
    "print(UrlToronto)\n",
    "temporal ='carpeta_temporal'\n",
    "downloader = UrlToronto(temporal)\n",
    "path_csv = downloader.download_csv('2023', '01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si lo habéis hecho bien, esta celda no debe producir ninguna salida\n",
    "assert(path_csv == 'carpeta_temporal\\\\bikeshare-ridership-2023/Bike share ridership 2023-01.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Trip Id', 'Trip  Duration', 'Start Station Id', 'Start Time', 'Start Station Name', 'End Station Id', 'End Time', 'End Station Name', 'Bike Id', 'User Type']\n"
     ]
    }
   ],
   "source": [
    "from  toronto_bike.BikeToronto import BikeToronto\n",
    "\n",
    "params = 'parametros.json'\n",
    "year = '2023'\n",
    "month = '05'\n",
    "\n",
    "# implementar las llamadas para la creación del dataframe\n",
    "bike_toronto = BikeToronto(params)\n",
    "\n",
    "df = bike_toronto.crear_df(year, month)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si lo habéis hecho bien, esta celda no debe producir ninguna salida\n",
    "assert(len(df.columns) == 10)\n",
    "assert(df.count() == 589217)\n",
    "dtypes = dict(df.dtypes)\n",
    "assert(dtypes['Bike Id'] == \"int\")\n",
    "assert(dtypes[\"Start Station Name\"] == 'string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Trip Id: integer (nullable = true)\n",
      " |-- Trip  Duration: integer (nullable = true)\n",
      " |-- Start Station Id: integer (nullable = true)\n",
      " |-- Start Time: timestamp (nullable = true)\n",
      " |-- Start Station Name: string (nullable = true)\n",
      " |-- End Station Id: integer (nullable = true)\n",
      " |-- End Time: timestamp (nullable = true)\n",
      " |-- End Station Name: string (nullable = true)\n",
      " |-- Bike Id: integer (nullable = true)\n",
      " |-- User Type: string (nullable = true)\n",
      " |-- Trip Duration Minutos: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_casual, df_anual = bike_toronto.procesar_df(df)\n",
    "assert(df_casual.count() + df_anual.count() == df.count())\n",
    "assert(len(df.columns) == 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests\n",
    "\n",
    "Define los tests que creas necesarios para comprobar que las clases funcionan correctamente. Los tests deberán estar en un directorio independiente, dentro del proyecto, pero no en el paquete que se distibuye.\n",
    "\n",
    "## Docstrings  y anotaciones de tipos\n",
    "\n",
    "Completar los docstring de todas las funciones. Anotar los tipos de las funciones.\n",
    "\n",
    "\n",
    "## Entrega en el CV\n",
    "La entrega consisitirá en un fichero comprimido `zip` con lo siguiente:\n",
    "- Fichero `whl` con el instalable del paquete generado\n",
    "- Los ficheros del paquete desarrollado, incluyendo los tests.\n",
    "- Este cuaderno de jupyter con las pruebas necesarias usando la clase `BikeToronto`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  },
  "nbTranslate": {
   "displayLangs": [
    "en",
    "es"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "es",
   "targetLang": "en",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "224px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
